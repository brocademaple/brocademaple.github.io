<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
        
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>【大模型应用】240922内容分享 |  私の宝庫です</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/images/ayer.png" />
       
<link rel="stylesheet" href="/dist/main.css">

      
<link rel="stylesheet" href="/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    </head>
  </html>
</html>


<body>
  <div id="app">
    
      <canvas class="fireworks"></canvas>
      <style>
        .fireworks {
          position: fixed;
          left: 0;
          top: 0;
          z-index: 99999;
          pointer-events: none;
        }
      </style>
      
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-CS_Notes/AI/【大模型应用】240922内容分享"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  【大模型应用】240922内容分享
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2024/09/21/CS_Notes/AI/%E3%80%90%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E3%80%91240922%E5%86%85%E5%AE%B9%E5%88%86%E4%BA%AB/" class="article-date">
  <time datetime="2024-09-20T16:00:00.000Z" itemprop="datePublished">2024-09-21</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/notes/">notes</a> / <a class="article-category-link" href="/categories/notes/developing-notes/">developing notes</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">10.9k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">41 分钟</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <h1>【大模型应用】240922内容分享</h1>
<p>[TOC]</p>
<h3 id="一、如何从零构建一个大模型"><a class="header-anchor" href="#一、如何从零构建一个大模型">¶</a>一、如何从零构建一个大模型</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"># 内容来源：橙篇</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">一、确定目标和需求</span><br><span class="line">	首先，需要明确大模型的构建目标和应用场景。这包括确定模型将用于哪些任务（如自然语言处理、图像识别、语音识别等），以及期望的性能指标和输出形式。</span><br><span class="line">	例子：假设我们的目标是构建一个用于自然语言处理（NLP）的大模型，用于回答用户的问题和生成文本。</span><br><span class="line"></span><br><span class="line">二、收集数据</span><br><span class="line">	大模型的训练需要大量的数据作为支撑。这些数据应该涵盖各种主题、语境、语法结构和风格，以确保模型的泛化能力。</span><br><span class="line">	例子：对于NLP大模型，我们需要收集各种来源的文本数据，如新闻报道、学术论文、社交媒体内容、书籍等。这些数据应该被清洗、去噪并转换成适合模型训练的格式。</span><br><span class="line"></span><br><span class="line">三、数据预处理</span><br><span class="line">	在将数据输入模型之前，需要进行一系列预处理操作，如分词、去停用词、词嵌入等。这些操作有助于将原始文本转换为模型可以理解和处理的形式。</span><br><span class="line">	例子：对于NLP大模型，我们可以使用分词工具将文本切分成词语或子词单元，并去除停用词以减少噪声。同时，可以使用词嵌入技术将词语转换为高维向量，以便模型捕捉词语之间的语义关系。</span><br><span class="line"></span><br><span class="line">四、选择模型架构</span><br><span class="line">	根据任务需求和可用资源选择合适的模型架构。常见的模型架构包括循环神经网络（RNN）、长短期记忆网络（LSTM）、Transformer等。</span><br><span class="line">	例子：对于NLP大模型，我们可以选择基于Transformer的架构，如GPT（Generative Pre-trained Transformer）系列模型。这些模型在自然语言生成和理解方面表现出色，并且具有强大的泛化能力。</span><br><span class="line"></span><br><span class="line">五、配置训练环境</span><br><span class="line">	准备训练所需的硬件和软件环境，包括高性能计算资源（如GPU集群）、深度学习框架（如TensorFlow、PyTorch）和必要的库（如NumPy、Pandas等）。</span><br><span class="line">	例子：为了训练一个大型的NLP模型，我们需要一个具有多个GPU的服务器集群，并安装PyTorch或TensorFlow等深度学习框架。同时，我们还需要安装各种必要的库和工具，以便进行数据处理和模型训练。</span><br><span class="line"></span><br><span class="line">六、训练模型</span><br><span class="line">	使用预处理后的数据和选定的模型架构进行模型训练。训练过程可能涉及多个阶段，包括预训练和微调。</span><br><span class="line">	例子：对于NLP大模型，我们可以首先使用大规模的无标签文本数据进行预训练，以学习通用的语言表示。然后，使用有标签的数据对模型进行微调，以适应特定的任务需求。训练过程中需要监控模型的性能指标，并调整超参数以优化模型性能。</span><br><span class="line"></span><br><span class="line">七、评估和调优</span><br><span class="line">	使用验证集或测试集评估模型的性能，并根据评估结果进行模型调优。调优可能涉及调整模型架构、超参数或训练策略等。</span><br><span class="line">	例子：在NLP大模型的评估阶段，我们可以使用标准的测试集来评估模型的性能，如准确率、召回率、F1分数等。根据评估结果，我们可以对模型进行微调以改善性能。这可能包括调整模型的层数、注意力机制的设置或学习率等超参数。</span><br><span class="line"></span><br><span class="line">八、部署和应用</span><br><span class="line">	将训练好的模型部署到实际应用中，并监控其性能以确保稳定运行。同时，根据用户反馈和实际需求进行模型更新和迭代。</span><br><span class="line">	例子：对于NLP大模型的应用，我们可以将其部署到问答系统、文本生成系统或对话系统中。在实际应用中，我们需要监控模型的响应速度和准确性，并根据用户反馈进行必要的更新和优化。</span><br><span class="line"></span><br><span class="line">总结</span><br><span class="line">	从零构建一个大模型是一个复杂而系统的过程，涉及多个阶段和多个方面的知识和技能。</span><br><span class="line">	通过明确目标和需求、收集数据、数据预处理、选择模型架构、配置训练环境、训练模型、评估和调优以及部署和应用等步骤，我们可以逐步构建出具有强大性能和应用价值的大模型。在实际操作中，需要根据具体情况灵活调整和优化各个步骤中的策略和参数。</span><br></pre></td></tr></table></figure>
<h3 id="二、数据预操作处理详析"><a class="header-anchor" href="#二、数据预操作处理详析">¶</a>二、数据预操作处理详析</h3>
<h4 id="1-分词（Tokenization）"><a class="header-anchor" href="#1-分词（Tokenization）">¶</a>1. 分词（Tokenization）</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">分词是将文本拆分成独立的单词、短语、符号或其他有意义的最小单位</span><br><span class="line">对于英文等使用空格分隔的语言，分词相对简单，只需按空格切分即可</span><br><span class="line">但对于中文等不使用空格分词的语言，分词难度较大，需要使用分词工具如 Jieba 来完成。</span><br></pre></td></tr></table></figure>
<p><strong>示例：</strong></p>
<ul>
<li>原始文本（中文）：<code>大唐不夜城是西安市的一处著名景点。</code></li>
<li>分词结果：<code>['大唐不夜城', '是', '西安市', '的', '一处', '著名', '景点', '。']</code></li>
<li>原始文本（英文）：<code>Natural language processing is a fascinating field.</code></li>
<li>分词结果：<code>['Natural', 'language', 'processing', 'is', 'a', 'fascinating', 'field', '.']</code></li>
</ul>
<h4 id="2-去停用词（Stop-Words-Removal）"><a class="header-anchor" href="#2-去停用词（Stop-Words-Removal）">¶</a>2. 去停用词（Stop Words Removal）</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">停用词是指那些在特定语言中使用频率很高但对文本含义贡献较少的词语，如中文的“的”、“是”、“在”或英文的“the”、“is”、“in”等。</span><br><span class="line">去除这些词语有助于减少文本噪音，提高模型的性能。</span><br></pre></td></tr></table></figure>
<p><strong>示例：</strong></p>
<ul>
<li>分词结果（中文）：<code>['大唐不夜城', '是', '西安市', '的', '一处', '著名', '景点', '。']</code></li>
<li>去停用词结果：<code>['大唐不夜城', '西安市', '著名', '景点']</code></li>
<li>分词结果（英文）：<code>['Natural', 'language', 'processing', 'is', 'a', 'fascinating', 'field', '.']</code></li>
<li>去停用词结果：<code>['Natural', 'language', 'processing', 'fascinating', 'field']</code></li>
</ul>
<h4 id="3-词嵌入（Word-Embedding）"><a class="header-anchor" href="#3-词嵌入（Word-Embedding）">¶</a>3. 词嵌入（Word Embedding）</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">词嵌入是将单词转换为具有固定维度的稠密向量，以便模型能够理解和处理。词嵌入方法包括 Word2Vec、GloVe、BERT 等。</span><br><span class="line">每个单词被表示为一个实数向量，向量之间的距离可以反映单词的语义相似性。</span><br></pre></td></tr></table></figure>
<p><strong>示例：</strong></p>
<ul>
<li>
<p>假设分词结果为：<code>['大唐不夜城', '西安市', '著名', '景点']</code></p>
</li>
<li>
<p>词嵌入结果（每个词映射为一个维度为 3 的向量）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">arduino复制代码&#x27;大唐不夜城&#x27; -&gt; [0.23, 0.45, -0.12]</span><br><span class="line">&#x27;西安市&#x27; -&gt; [0.67, 0.98, -0.34]</span><br><span class="line">&#x27;著名&#x27; -&gt; [0.11, -0.09, 0.56]</span><br><span class="line">&#x27;景点&#x27; -&gt; [0.37, 0.12, 0.42]</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="4-词形还原（Lemmatization）与词干提取（Stemming）"><a class="header-anchor" href="#4-词形还原（Lemmatization）与词干提取（Stemming）">¶</a>4. 词形还原（Lemmatization）与词干提取（Stemming）</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">词形还原是将单词还原为其基本形式（如动词的原形），</span><br><span class="line">而词干提取则是将单词截断为词干。</span><br><span class="line">词形还原能保留更多的词汇信息，</span><br><span class="line">而词干提取可能会截断得过于简单，但处理速度较快。</span><br></pre></td></tr></table></figure>
<p><strong>示例：</strong></p>
<ul>
<li>原始文本（英文）：<code>running</code>, <code>ran</code>, <code>runs</code></li>
<li>词形还原结果：<code>run</code></li>
<li>词干提取结果：<code>run</code></li>
</ul>
<h3 id="三、模型架构详析"><a class="header-anchor" href="#三、模型架构详析">¶</a>三、模型架构详析</h3>
<h4 id="1-循环神经网络（RNN-Recurrent-Neural-Network）"><a class="header-anchor" href="#1-循环神经网络（RNN-Recurrent-Neural-Network）">¶</a>1. 循环神经网络（RNN, Recurrent Neural Network）</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">RNN 是一种用于处理序列数据的神经网络，能够有效地捕捉序列中的上下文关系。</span><br><span class="line">它的特点是具有“记忆”功能，能够将前一时刻的输出和当前输入结合起来影响当前的输出。</span><br><span class="line">RNN 的核心特性是能够通过隐藏状态（hidden state）来捕捉序列中的时间依赖性。</span><br><span class="line">RNN 会在序列的每一个时间步（time step）上使用相同的网络参数，并通过隐藏状态将前一时间步的信息传递给下一时间步。</span><br><span class="line">RNN 适合处理时间序列、文本等依赖于上下文顺序的数据。</span><br></pre></td></tr></table></figure>
<h5 id="工作流程"><a class="header-anchor" href="#工作流程">¶</a>工作流程</h5>
<ul>
<li><strong>输入层</strong>：输入序列的每个元素逐个输入网络。</li>
<li><strong>隐藏层</strong>：每个时间步的隐藏状态是由当前输入和前一时间步的隐藏状态共同决定的。</li>
<li><strong>输出层</strong>：最终的隐藏状态或所有时间步的隐藏状态可以用于预测输出。</li>
</ul>
<h5 id="优缺点"><a class="header-anchor" href="#优缺点">¶</a>优缺点</h5>
<ul>
<li><strong>优点</strong>：适合处理时间序列数据（如天气预测、股票预测）和自然语言数据（如文本生成、语音识别）。</li>
<li><strong>缺点</strong>：在长序列中，容易出现梯度消失或梯度爆炸问题，难以捕捉长时间依赖关系。</li>
</ul>
<h5 id="举例"><a class="header-anchor" href="#举例">¶</a>举例</h5>
<ul>
<li>应用于文本生成任务，如给定一段文本前面的若干个单词，预测下一个单词。</li>
</ul>
<h4 id="2-长短期记忆网络（LSTM）"><a class="header-anchor" href="#2-长短期记忆网络（LSTM）">¶</a>2. 长短期记忆网络（LSTM）</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">LSTM 是 RNN 的一种变体，用于解决 RNN 的梯度消失问题。</span><br><span class="line">LSTM 引入了三个门（input gate、forget gate、output gate）和一个细胞状态（cell state），通过门控机制来控制信息的流动，从而可以更好地捕捉长时间依赖。</span><br></pre></td></tr></table></figure>
<h5 id="工作流程-v2"><a class="header-anchor" href="#工作流程-v2">¶</a>工作流程</h5>
<ul>
<li><strong>输入门（Input Gate）</strong>：决定当前输入信息的重要性。</li>
<li><strong>遗忘门（Forget Gate）</strong>：决定细胞状态中哪些信息需要被遗忘。</li>
<li><strong>输出门（Output Gate）</strong>：决定哪些信息会被输出作为隐藏状态。</li>
</ul>
<h5 id="优缺点-v2"><a class="header-anchor" href="#优缺点-v2">¶</a>优缺点</h5>
<ul>
<li><strong>优点</strong>：能够捕捉长时间的依赖关系，适合长序列的处理，如机器翻译、问答系统、语音生成。</li>
<li><strong>缺点</strong>：相比 RNN 更加复杂，训练时间较长，计算开销较大。</li>
</ul>
<h5 id="举例-v2"><a class="header-anchor" href="#举例-v2">¶</a>举例</h5>
<p>应用于机器翻译任务，例如给定英文句子“Hello world”，预测对应的中文句子“你好，世界”。</p>
<h4 id="3-Transformer"><a class="header-anchor" href="#3-Transformer">¶</a>3. Transformer</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Transformer 是一种基于自注意力（Self-Attention）机制的序列到序列模型架构。</span><br><span class="line">与 RNN 和 LSTM 不同，Transformer 不依赖于序列的顺序处理数据，而是通过自注意力机制能够同时关注序列中的所有位置。</span><br><span class="line">它由编码器（Encoder）和解码器（Decoder）组成。</span><br></pre></td></tr></table></figure>
<h5 id="工作流程-v3"><a class="header-anchor" href="#工作流程-v3">¶</a>工作流程</h5>
<ul>
<li><strong>自注意力机制（Self-Attention）</strong>：每个位置的表示向量与其他位置的表示向量进行交互，捕捉全局信息。</li>
<li><strong>多头注意力（Multi-Head Attention）</strong>：使用多个注意力机制头来捕捉不同的语义信息。</li>
<li><strong>位置编码（Position Encoding）</strong>：加入位置信息来保持序列的顺序性。</li>
</ul>
<h5 id="优缺点-v3"><a class="header-anchor" href="#优缺点-v3">¶</a>优缺点</h5>
<ul>
<li><strong>优点</strong>：并行计算效率高，适合处理长序列，效果优于 RNN 和 LSTM，适用于各种自然语言处理任务，如机器翻译、文本摘要、情感分析等。</li>
<li><strong>缺点</strong>：模型参数多，计算资源需求较大。</li>
</ul>
<h5 id="举例-v3"><a class="header-anchor" href="#举例-v3">¶</a>举例</h5>
<p>应用于机器翻译任务，如“Hello world”到“你好，世界”的翻译。Transformer 在这类任务中往往比 LSTM 表现更好。</p>
<h4 id="4-如何选择模型架构"><a class="header-anchor" href="#4-如何选择模型架构">¶</a>4. 如何选择模型架构</h4>
<ul>
<li>
<p>如果任务涉及较短的序列数据，且对资源要求较低，可以选择 RNN。</p>
</li>
<li>
<p>如果任务要求捕捉长时间的依赖关系，如长文本或长时间序列数据，且资源充足，LSTM 是更好的选择。</p>
</li>
<li>
<p>如果任务对精度要求高且计算资源丰富，尤其是处理长序列数据或复杂自然语言任务（如机器翻译、大规模文本生成等），Transformer 是首选。</p>
</li>
</ul>
<h3 id="四、模型训练环境详析"><a class="header-anchor" href="#四、模型训练环境详析">¶</a>四、模型训练环境详析</h3>
<h4 id="1-高性能计算资源（如-GPU-集群）"><a class="header-anchor" href="#1-高性能计算资源（如-GPU-集群）">¶</a>1. 高性能计算资源（如 GPU 集群）</h4>
<h5 id="1-1-GPU（图形处理单元）"><a class="header-anchor" href="#1-1-GPU（图形处理单元）">¶</a>1.1  GPU（图形处理单元）</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GPU 是专为并行计算设计的硬件，最初用于图像处理，但现在广泛应用于深度学习和科学计算。</span><br><span class="line">与 CPU 相比，GPU 可以更高效地处理大规模矩阵运算，非常适合训练神经网络。</span><br></pre></td></tr></table></figure>
<h6 id="优势"><a class="header-anchor" href="#优势">¶</a>优势</h6>
<ul>
<li><strong>并行计算能力强</strong>：能够同时处理大量计算任务，非常适合训练需要大量矩阵运算的深度学习模型。</li>
<li><strong>高效的浮点运算能力</strong>：在神经网络训练中，涉及大量的浮点数计算，GPU 的多核架构可以快速完成这些任务。</li>
</ul>
<h6 id="例子"><a class="header-anchor" href="#例子">¶</a>例子</h6>
<ul>
<li>NVIDIA 的 Tesla、A100、V100 系列是专为深度学习设计的高性能 GPU。</li>
</ul>
<h5 id="1-2-GPU-集群"><a class="header-anchor" href="#1-2-GPU-集群">¶</a>1.2  GPU 集群</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GPU 集群是由多个 GPU 设备组成的计算集群，用于处理超大规模的深度学习任务。</span><br><span class="line">集群中的 GPU 可以并行协作，加快训练速度，特别适合大规模模型或大数据集的训练任务。</span><br></pre></td></tr></table></figure>
<h6 id="优势-v2"><a class="header-anchor" href="#优势-v2">¶</a>优势</h6>
<ul>
<li><strong>扩展性好</strong>：多个 GPU 可以协同工作，提升训练速度。</li>
<li><strong>大模型训练</strong>：对于一些需要大量计算资源的大模型（如 GPT-3），只有通过 GPU 集群才能在合理的时间内完成训练。</li>
</ul>
<h6 id="例子-v2"><a class="header-anchor" href="#例子-v2">¶</a>例子</h6>
<ul>
<li>亚马逊 AWS 的 EC2 P3 实例、谷歌的 TPU Pods 以及 NVIDIA 的 DGX 系列都提供了 GPU 集群服务。</li>
</ul>
<h4 id="2-深度学习框架"><a class="header-anchor" href="#2-深度学习框架">¶</a>2. 深度学习框架</h4>
<h5 id="2-1-TensorFlow"><a class="header-anchor" href="#2-1-TensorFlow">¶</a>2.1  TensorFlow</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">TensorFlow 是 Google 开发的一个开源深度学习框架。</span><br><span class="line">它支持多平台、多设备的高效计算，并且拥有强大的生态系统和丰富的工具集。</span><br></pre></td></tr></table></figure>
<h6 id="特点"><a class="header-anchor" href="#特点">¶</a>特点</h6>
<ul>
<li><strong>灵活性高</strong>：支持静态图（静态计算图）和动态图（Eager Execution）模式，可以根据需求选择不同的计算方式。</li>
<li><strong>生态系统完善</strong>：拥有 TensorBoard（可视化工具）、TensorFlow Serving（部署）等丰富的工具。</li>
</ul>
<h6 id="例子-v3"><a class="header-anchor" href="#例子-v3">¶</a>例子</h6>
<p>用于各种计算机视觉任务（如图像分类、目标检测）、自然语言处理任务（如文本生成、情感分析）等。</p>
<h5 id="2-2-PyTorch"><a class="header-anchor" href="#2-2-PyTorch">¶</a>2.2  PyTorch</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PyTorch 是由 Facebook 开发的深度学习框架，以动态计算图和灵活性著称，近年来在学术界和工业界都非常流行。</span><br></pre></td></tr></table></figure>
<h6 id="特点-v2"><a class="header-anchor" href="#特点-v2">¶</a>特点</h6>
<ul>
<li><strong>动态图机制</strong>：计算图可以在运行时动态构建，便于调试和实验，特别适合研究人员和快速原型开发。</li>
<li><strong>直观性强</strong>：代码风格接近 Python，便于理解和使用。</li>
</ul>
<h6 id="例子-v4"><a class="header-anchor" href="#例子-v4">¶</a>例子</h6>
<p>用于自然语言处理（如 BERT、GPT 系列模型）、计算机视觉（如 ResNet、YOLO）等任务。</p>
<h4 id="3-必要的Python库"><a class="header-anchor" href="#3-必要的Python库">¶</a>3. 必要的Python库</h4>
<h5 id="3-1-NumPy"><a class="header-anchor" href="#3-1-NumPy">¶</a>3.1  NumPy</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">NumPy 是 Python 中的基础科学计算库，提供了高效的多维数组（ndarray）操作和各种数学函数。</span><br></pre></td></tr></table></figure>
<h6 id="特点-v3"><a class="header-anchor" href="#特点-v3">¶</a>特点</h6>
<ul>
<li><strong>多维数组支持</strong>：高效的多维数组（ndarray）操作。</li>
<li><strong>丰富的数学函数</strong>：支持矩阵运算、线性代数、统计学函数等。</li>
</ul>
<h6 id="例子-v5"><a class="header-anchor" href="#例子-v5">¶</a>例子</h6>
<p>在深度学习中用于数据预处理，如归一化、矩阵运算等。</p>
<h5 id="3-2-Pandas"><a class="header-anchor" href="#3-2-Pandas">¶</a>3.2  Pandas</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pandas 是一个强大的数据分析和数据处理库，提供了便捷的数据结构（如 DataFrame）和数据操作工具。</span><br></pre></td></tr></table></figure>
<h6 id="特点-v4"><a class="header-anchor" href="#特点-v4">¶</a>特点</h6>
<ul>
<li><strong>数据处理便捷</strong>：支持数据清洗、转换、聚合等操作。</li>
<li><strong>与其他库兼容性好</strong>：可以与 NumPy、Matplotlib 等库很好地结合使用。</li>
</ul>
<h6 id="例子-v6"><a class="header-anchor" href="#例子-v6">¶</a>例子</h6>
<p>用于数据分析和特征工程，如从 CSV 文件中读取数据、数据清洗、缺失值处理等。</p>
<h4 id="4-实际训练大模型的基本流程"><a class="header-anchor" href="#4-实际训练大模型的基本流程">¶</a>4. 实际训练大模型的基本流程</h4>
<ol>
<li>
<p><strong>选择硬件资源</strong>：根据模型的大小和数据集的规模，选择合适的硬件资源，如单个 GPU、多个 GPU 或 GPU 集群。</p>
<blockquote>
<p>自分の感受：在本地电脑使用云服务器（3090Ti）部署的大模型可以跑，但是跑的速度比较慢</p>
<p>类似ChatGPT和kimi这种可以迅速做出反应的模型，应该就是在GPU集群上面跑的：）</p>
</blockquote>
</li>
<li>
<p><strong>配置软件环境</strong>：安装所需的深度学习框架（如 TensorFlow、PyTorch）和辅助库（NumPy、Pandas 等）。</p>
</li>
<li>
<p><strong>数据预处理</strong>：使用 Pandas、NumPy 等库对数据进行预处理，包括数据清洗、归一化、数据增强等操作。</p>
</li>
<li>
<p><strong>构建模型</strong>：使用深度学习框架构建神经网络模型，包括定义模型结构、损失函数和优化器。</p>
</li>
<li>
<p><strong>训练模型</strong>：将预处理后的数据输入模型，进行训练过程，包括前向传播、计算损失、反向传播、更新权重等步骤。</p>
</li>
<li>
<p><strong>评估模型</strong>：在测试集上评估模型的性能，如准确率、损失值等。</p>
</li>
<li>
<p><strong>部署模型</strong>：将训练好的模型部署到生产环境中，供用户使用。</p>
</li>
</ol>
<h3 id="五、模型训练详析"><a class="header-anchor" href="#五、模型训练详析">¶</a>五、模型训练详析</h3>
<blockquote>
<p>以下内容结合现在的任务情况：已经以xlsx的形式收集了数据，怎么放到云服务器部署的大模型中</p>
</blockquote>
<h4 id="1-数据预处理"><a class="header-anchor" href="#1-数据预处理">¶</a>1. 数据预处理</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">将原始数据处理为模型能够理解的格式</span><br></pre></td></tr></table></figure>
<ol>
<li>读取xlsx文件</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 pandas 库读取 Excel 文件，将数据转为 DataFrame 格式</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_excel(<span class="string">&#x27;your_file.xlsx&#x27;</span>)</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>数据清洗</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 移除无效数据、重复数据，填充缺失值</span></span><br><span class="line"><span class="comment"># 去除 HTML 标签、特殊符号等噪声数据</span></span><br><span class="line"></span><br><span class="line">data = data.dropna()  <span class="comment"># 删除缺失值</span></span><br><span class="line">data = data.drop_duplicates()  <span class="comment"># 删除重复值</span></span><br></pre></td></tr></table></figure>
<ol start="3">
<li>数据格式转换</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将数据转为文本格式，并根据任务需求组织为问答对、上下文-问题对等</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设你的数据包含 &quot;问题&quot; 和 &quot;回答&quot; 两列</span></span><br><span class="line">questions = data[<span class="string">&#x27;问题&#x27;</span>].tolist()</span><br><span class="line">answers = data[<span class="string">&#x27;回答&#x27;</span>].tolist()</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>文本分词和标注（可选）</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对文本数据进行分词处理，或者进行其他特定的标注，如 NER（命名实体识别）</span></span><br><span class="line"><span class="comment"># 可以使用 jieba 等分词工具</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line">data[<span class="string">&#x27;分词文本&#x27;</span>] = data[<span class="string">&#x27;原始文本&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="string">&#x27; &#x27;</span>.join(jieba.cut(x)))</span><br></pre></td></tr></table></figure>
<h4 id="2-预训练（Pre-training）"><a class="header-anchor" href="#2-预训练（Pre-training）">¶</a>2. 预训练（Pre-training）</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">预训练是指在大规模无标签数据上训练语言模型，让模型学习通用的语言表示</span><br></pre></td></tr></table></figure>
<h5 id="1-使用现有的预训练模型"><a class="header-anchor" href="#1-使用现有的预训练模型">¶</a>1. 使用现有的预训练模型</h5>
<ul>
<li><code>Langchain Chatchat </code>框架中可能已经包含了预训练的模型，比如 GPT 系列模型</li>
<li>可以直接加载这些模型进行微调</li>
</ul>
<h5 id="2-自行预训练（不推荐初学者）"><a class="header-anchor" href="#2-自行预训练（不推荐初学者）">¶</a>2. 自行预训练（不推荐初学者）</h5>
<ul>
<li>如果有大规模无标签数据（如维基百科、开源书籍等），可以在这些数据上从头开始训练模型。但这需要非常高的计算资源</li>
</ul>
<h4 id="3-微调（Fine-tuning）"><a class="header-anchor" href="#3-微调（Fine-tuning）">¶</a>3. 微调（Fine-tuning）</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">微调是将预训练的语言模型应用到特定任务上的过程</span><br></pre></td></tr></table></figure>
<ol>
<li>数据准备</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将预处理好的问答对（或其他形式的数据）分为训练集和验证集</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_data, val_data = train_test_split(data, test_size=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>定义训练脚本</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 Langchain 或 Hugging Face 的 transformers 库定义模型和训练参数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments</span><br><span class="line"></span><br><span class="line">model_name = <span class="string">&quot;gpt2&quot;</span></span><br><span class="line">tokenizer = GPT2Tokenizer.from_pretrained(model_name)</span><br><span class="line">model = GPT2LMHeadModel.from_pretrained(model_name)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize_function</span>(<span class="params">examples</span>):</span><br><span class="line">    <span class="keyword">return</span> tokenizer(examples[<span class="string">&quot;text&quot;</span>], padding=<span class="string">&quot;max_length&quot;</span>, truncation=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设 data 是一个有 “text” 列的 DataFrame</span></span><br><span class="line">tokenized_data = data.<span class="built_in">map</span>(tokenize_function, batched=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>训练模型</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置训练参数并启动训练。可以使用 GPU 集群加速训练</span></span><br><span class="line"></span><br><span class="line">training_args = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">&quot;./results&quot;</span>,</span><br><span class="line">    evaluation_strategy=<span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">4</span>,</span><br><span class="line">    per_device_eval_batch_size=<span class="number">4</span>,</span><br><span class="line">    num_train_epochs=<span class="number">3</span>,</span><br><span class="line">    weight_decay=<span class="number">0.01</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=training_args,</span><br><span class="line">    train_dataset=train_data,</span><br><span class="line">    eval_dataset=val_data,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>保存模型</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将微调后的模型保存，以便后续使用</span></span><br><span class="line"></span><br><span class="line">model.save_pretrained(<span class="string">&quot;fine_tuned_model&quot;</span>)</span><br><span class="line">tokenizer.save_pretrained(<span class="string">&quot;fine_tuned_model&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="4-模型评估"><a class="header-anchor" href="#4-模型评估">¶</a>4. 模型评估</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在验证集上评估模型性能，如困惑度（Perplexity），并根据结果调整超参数（如学习率、批大小等），以优化模型性能</span><br></pre></td></tr></table></figure>
<h5 id="评估指标"><a class="header-anchor" href="#评估指标">¶</a>评估指标</h5>
<ul>
<li>困惑度（Perplexity）：评估生成模型对数据的拟合程度。</li>
<li>准确率（Accuracy）、F1 值（F1-score）：评估分类模型的表现。</li>
</ul>
<h5 id="模型调优"><a class="header-anchor" href="#模型调优">¶</a>模型调优</h5>
<ul>
<li>通过观察损失值的变化、验证集上的性能指标，调整模型的超参数或数据预处理策略。</li>
</ul>
<h4 id="5-实际应用建议"><a class="header-anchor" href="#5-实际应用建议">¶</a>5. 实际应用建议</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">你可以将大唐不夜城的问答数据集用于微调一个 GPT 模型，使得模型能够回答关于该旅游景点的具体问题。</span><br><span class="line">在 Langchain Chatchat 的框架中，可以使用微调后的模型作为回答模块，通过 API 与前端交互，实现智能问答功能。</span><br></pre></td></tr></table></figure>
<h3 id="六、问答对生成建议"><a class="header-anchor" href="#六、问答对生成建议">¶</a>六、问答对生成建议</h3>
<blockquote>
<p>来自ChatGPT，但是具体实现还要进行调整</p>
</blockquote>
<h4 id="1-数据理解与提取"><a class="header-anchor" href="#1-数据理解与提取">¶</a>1. 数据理解与提取</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">先对已有数据进行理解和提取，以确定内容的类别和结构，然后根据大类和小类生成问题</span><br></pre></td></tr></table></figure>
<h5 id="1-1-数据理解"><a class="header-anchor" href="#1-1-数据理解">¶</a>1.1  数据理解</h5>
<ul>
<li>
<p><strong>大类</strong>：可能是“历史背景”、“文化意义”、“地理位置”、“著名景点”等。</p>
</li>
<li>
<p><strong>小类</strong>：可能是某个景点的具体描述、某个事件的历史背景等。</p>
</li>
</ul>
<h5 id="1-2-数据提取"><a class="header-anchor" href="#1-2-数据提取">¶</a>1.2  数据提取</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 pandas 库读取 xlsx 文件，将数据整理为适合处理的格式</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取Excel文件</span></span><br><span class="line">data = pd.read_excel(<span class="string">&#x27;datang_baike.xlsx&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设大类为&#x27;Category&#x27;，小类为&#x27;Subcategory&#x27;，内容为&#x27;Content&#x27;</span></span><br><span class="line">categories = data[<span class="string">&#x27;Category&#x27;</span>].unique()</span><br><span class="line">subcategories = data[<span class="string">&#x27;Subcategory&#x27;</span>].unique()</span><br></pre></td></tr></table></figure>
<h4 id="2-生成问答对"><a class="header-anchor" href="#2-生成问答对">¶</a>2. 生成问答对</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">根据每个小类生成问答对</span><br></pre></td></tr></table></figure>
<h5 id="2-1-基本问答对生成"><a class="header-anchor" href="#2-1-基本问答对生成">¶</a>2.1  基本问答对生成</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对每一个小类，根据内容生成标准问题和答案。</span></span><br><span class="line"><span class="comment"># 生成问题：可以从小类的名称或内容中提取，比如“小雁塔的历史背景是什么？”</span></span><br><span class="line"><span class="comment"># 生成答案：从小类的内容字段中提取答案。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成问答对</span></span><br><span class="line">qa_pairs = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx, row <span class="keyword">in</span> data.iterrows():</span><br><span class="line">    question = <span class="string">f&quot;<span class="subst">&#123;row[<span class="string">&#x27;Subcategory&#x27;</span>]&#125;</span>是什么？&quot;</span></span><br><span class="line">    answer = row[<span class="string">&#x27;Content&#x27;</span>]</span><br><span class="line">    qa_pairs.append(&#123;<span class="string">&quot;question&quot;</span>: question, <span class="string">&quot;answer&quot;</span>: answer&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将问答对保存为DataFrame</span></span><br><span class="line">qa_df = pd.DataFrame(qa_pairs)</span><br></pre></td></tr></table></figure>
<h5 id="2-2-使用模板生成多种问题"><a class="header-anchor" href="#2-2-使用模板生成多种问题">¶</a>2.2 使用模板生成多种问题</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一些常见的提问模板</span></span><br><span class="line">templates = [</span><br><span class="line">    <span class="string">&quot;&#123;subcategory&#125;的详细信息是什么？&quot;</span>,</span><br><span class="line">    <span class="string">&quot;你能告诉我一些关于&#123;subcategory&#125;的事情吗？&quot;</span>,</span><br><span class="line">    <span class="string">&quot;介绍一下&#123;subcategory&#125;。&quot;</span>,</span><br><span class="line">    <span class="string">&quot;&#123;subcategory&#125;有什么特别的？&quot;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成多个相似问题</span></span><br><span class="line">expanded_qa_pairs = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx, row <span class="keyword">in</span> data.iterrows():</span><br><span class="line">    <span class="keyword">for</span> template <span class="keyword">in</span> templates:</span><br><span class="line">        question = template.<span class="built_in">format</span>(subcategory=row[<span class="string">&#x27;Subcategory&#x27;</span>])</span><br><span class="line">        answer = row[<span class="string">&#x27;Content&#x27;</span>]</span><br><span class="line">        expanded_qa_pairs.append(&#123;<span class="string">&quot;question&quot;</span>: question, <span class="string">&quot;answer&quot;</span>: answer&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存到DataFrame</span></span><br><span class="line">expanded_qa_df = pd.DataFrame(expanded_qa_pairs)</span><br></pre></td></tr></table></figure>
<h4 id="3-相似问题生成"><a class="header-anchor" href="#3-相似问题生成">¶</a>3. 相似问题生成</h4>
<h5 id="3-1-基于规则的同义句生成"><a class="header-anchor" href="#3-1-基于规则的同义句生成">¶</a>3.1  基于规则的同义句生成</h5>
<ul>
<li>将问题中某些词替换为同义词，或使用不同的提问方式。</li>
<li>例如：“大唐不夜城在哪里？” -&gt; “请问大唐不夜城位于什么地方？”</li>
</ul>
<h5 id="3-2-使用自然语言处理工具"><a class="header-anchor" href="#3-2-使用自然语言处理工具">¶</a>3.2  使用自然语言处理工具</h5>
<ul>
<li>使用 NLP 工具（如 <code>nltk</code>、<code>spaCy</code> 等）或深度学习模型（如 <code>transformers</code> 中的 <code>paraphrase</code> 模型）生成多种相似问题</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用Hugging Face的paraphrase模型</span></span><br><span class="line">paraphrase_model = pipeline(<span class="string">&quot;paraphrase-multilingual-mpnet-base-v2&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成相似问题</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_similar_questions</span>(<span class="params">question</span>):</span><br><span class="line">    similar_questions = paraphrase_model(question)</span><br><span class="line">    <span class="keyword">return</span> [item[<span class="string">&#x27;generated_text&#x27;</span>] <span class="keyword">for</span> item <span class="keyword">in</span> similar_questions]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例：生成问题的多种形式</span></span><br><span class="line">question = <span class="string">&quot;大唐不夜城有什么景点？&quot;</span></span><br><span class="line">similar_questions = generate_similar_questions(question)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(similar_questions)</span><br></pre></td></tr></table></figure>
<h4 id="4-存储入数据库"><a class="header-anchor" href="#4-存储入数据库">¶</a>4. 存储入数据库</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">将生成的问答对和相似问题存储到数据库中，</span><br><span class="line">可以选择 MySQL、SQLite 或 MongoDB 等数据库系统</span><br></pre></td></tr></table></figure>
<h5 id="4-1-关系型数据库（如MySQL）"><a class="header-anchor" href="#4-1-关系型数据库（如MySQL）">¶</a>4.1 关系型数据库（如MySQL）</h5>
<h6 id="1-表结构设计"><a class="header-anchor" href="#1-表结构设计">¶</a>1. 表结构设计</h6>
<ul>
<li>
<p><code>questions</code> 表：存储原始问题及其类别、小类等信息</p>
</li>
<li>
<p><code>similar_questions</code> 表：存储相似问题及其对应的原始问题 ID</p>
</li>
</ul>
<h6 id="2-插入数据"><a class="header-anchor" href="#2-插入数据">¶</a>2. 插入数据</h6>
<ul>
<li>使用 <code>pandas</code> 的 <code>to_sql</code> 方法将 <code>DataFrame</code> 直接插入到数据库中</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="keyword">from</span> sqlalchemy <span class="keyword">import</span> create_engine</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立数据库连接</span></span><br><span class="line">engine = create_engine(<span class="string">&#x27;mysql+pymysql://username:password@localhost/dbname&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将问答对和相似问题插入数据库</span></span><br><span class="line">expanded_qa_df.to_sql(<span class="string">&#x27;questions&#x27;</span>, con=engine, if_exists=<span class="string">&#x27;replace&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h5 id="4-2-文档型数据库（如MongoDB）"><a class="header-anchor" href="#4-2-文档型数据库（如MongoDB）">¶</a>4.2 文档型数据库（如MongoDB）</h5>
<ol>
<li>文档结构设计</li>
</ol>
<ul>
<li><code>question_document</code>：包含原始问题、相似问题列表、答案等信息</li>
</ul>
<ol start="2">
<li>插入数据</li>
</ol>
<ul>
<li>使用 <code>pymongo </code>库将数据插入到 <code>MongoDB</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pymongo <span class="keyword">import</span> MongoClient</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立MongoDB连接</span></span><br><span class="line">client = MongoClient(<span class="string">&quot;mongodb://localhost:27017/&quot;</span>)</span><br><span class="line">db = client[<span class="string">&#x27;datang_db&#x27;</span>]</span><br><span class="line">collection = db[<span class="string">&#x27;questions&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 插入问答对</span></span><br><span class="line"><span class="keyword">for</span> idx, row <span class="keyword">in</span> expanded_qa_df.iterrows():</span><br><span class="line">    document = &#123;</span><br><span class="line">        <span class="string">&quot;question&quot;</span>: row[<span class="string">&#x27;question&#x27;</span>],</span><br><span class="line">        <span class="string">&quot;answer&quot;</span>: row[<span class="string">&#x27;answer&#x27;</span>],</span><br><span class="line">        <span class="string">&quot;similar_questions&quot;</span>: generate_similar_questions(row[<span class="string">&#x27;question&#x27;</span>])</span><br><span class="line">	&#125;</span><br><span class="line">    </span><br><span class="line">    collection.insert_one(document)</span><br></pre></td></tr></table></figure>
<h4 id="5-总结"><a class="header-anchor" href="#5-总结">¶</a>5. 总结</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">数据预处理：使用 pandas 对 Excel 文件中的内容进行整理</span><br><span class="line">问答对生成：根据小类内容生成标准问答对，使用模板生成多种形式的问题</span><br><span class="line">相似问题生成：使用 NLP 工具生成问题的多种相似形式</span><br><span class="line">存储到数据库：根据应用场景选择适合的数据库，将问答对和相似问题存储</span><br></pre></td></tr></table></figure>
<h3 id="七、数据库的选择（MySQL-MongoDB）"><a class="header-anchor" href="#七、数据库的选择（MySQL-MongoDB）">¶</a>七、数据库的选择（MySQL / MongoDB）</h3>
<h4 id="1-MySQL"><a class="header-anchor" href="#1-MySQL">¶</a>1. MySQL</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">- 优点</span><br><span class="line">	- 结构化数据：适合有【明确表结构和关系】的场景，如用户信息、交易记录等</span><br><span class="line">	- 事务支持：支持【事务操作】，适用于需要数据一致性的场景</span><br><span class="line">	- 复杂查询：支持复杂的 SQL 查询、JOIN 操作，适合【数据间关系复杂】的情况</span><br><span class="line">	- 数据完整性：通过外键约束、数据类型限制等机制保障【数据一致性和完整性】</span><br><span class="line">	</span><br><span class="line">- 缺点</span><br><span class="line">	- 【扩展性有限】：水平扩展（sharding）较为复杂</span><br><span class="line">	- 【灵活性不如】文档型数据库：对于不规则数据或数据结构经常变动的情况不太适合</span><br><span class="line">	</span><br><span class="line">- 适用场景</span><br><span class="line">	- 数据表结构清晰，字段和表之间关系明确</span><br><span class="line">	- 需要复杂的查询操作，比如 JOIN、聚合等</span><br><span class="line">	- 需要保证数据的一致性和完整性</span><br><span class="line">	- 数据不经常发生结构上的变化</span><br></pre></td></tr></table></figure>
<h4 id="2-MongoDB"><a class="header-anchor" href="#2-MongoDB">¶</a>2. MongoDB</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">- 优点</span><br><span class="line">	- 【灵活性强】：不需要预定义表结构，数据字段可以动态增加和改变，适合结构不固定的数据</span><br><span class="line">	- 水平扩展性好：天然支持分片（sharding），适合【大规模数据的存储和管理】</span><br><span class="line">	- 文档模型：使用 JSON/BSON 格式存储，查询和更新数据更灵活，尤其【适合嵌套结构的存储和查询】</span><br><span class="line">	- 适合大数据量：可以轻松【处理海量数据和高并发读写请求】</span><br><span class="line">	</span><br><span class="line">- 缺点</span><br><span class="line">	- 复杂查询支持不如关系型数据库：不支持传统 SQL 的 JOIN 操作，复杂查询需要设计合理的数据模型</span><br><span class="line">	- 缺乏事务性（较新版本已经支持多文档事务）：对于强一致性要求较高的场景不太适合</span><br><span class="line">	- 数据冗余问题：数据的去规范化设计（如嵌套文档）可能导致数据冗余</span><br><span class="line">	</span><br><span class="line">- 适用场景</span><br><span class="line">	- 【数据结构不固定】，字段和层次变化多，比如用户行为数据、日志数据、内容管理系统等</span><br><span class="line">	- 【高并发读写操作】，如实时数据、在线应用的后台</span><br><span class="line">	- 【数据规模大】，且需要横向扩展</span><br><span class="line">	- 不需要复杂的跨表查询，或者可以通过嵌套文档结构代替关联关系</span><br></pre></td></tr></table></figure>
<h4 id="3-针对项目需求的推荐"><a class="header-anchor" href="#3-针对项目需求的推荐">¶</a>3. 针对项目需求的推荐</h4>
<blockquote>
<p>来自：ChatGPT</p>
</blockquote>
<h5 id="项目特点"><a class="header-anchor" href="#项目特点">¶</a>项目特点</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">旅游信息数据：</span><br><span class="line">	大唐不夜城的旅游信息数据，可能包括景点介绍、历史背景、文化故事等，内容较为多样化，数据结构可能不完全统一</span><br><span class="line">问答对生成：</span><br><span class="line">	你希望生成多种形式的问答对和相似问题，这意味着数据的生成和变动比较频繁</span><br><span class="line">查询需求：</span><br><span class="line">	前端可能需要根据不同关键词、类别、景点名称进行查询，且需要支持一定的灵活查询</span><br><span class="line">扩展性：</span><br><span class="line">	后期可能会增加更多景点或景区的数据，需要数据库有一定的扩展能力</span><br></pre></td></tr></table></figure>
<h5 id="推荐"><a class="header-anchor" href="#推荐">¶</a>推荐</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">综合考虑你的需求，我会推荐使用 MongoDB，理由如下：</span><br><span class="line"></span><br><span class="line">	灵活的数据结构：景点描述、历史背景等数据字段可能变化较大，MongoDB 能够更好地适应这种不固定的结构</span><br><span class="line">	适合大数据量存储：如果你打算未来增加更多的旅游数据，MongoDB 的水平扩展能力会更好</span><br><span class="line">	文档模型易于查询：每个景点的信息可以存储为一个完整的文档，不同字段如“景点名称”、“历史背景”、“问答对”等都可以在一个文档中管理，查询时更加直观和方便</span><br></pre></td></tr></table></figure>
<blockquote>
<p>提问：是不是要换成MongoDB更好？</p>
</blockquote>
<h3 id="八、评估和调优详析"><a class="header-anchor" href="#八、评估和调优详析">¶</a>八、评估和调优详析</h3>
<h4 id="1-评估模型性能"><a class="header-anchor" href="#1-评估模型性能">¶</a>1.  评估模型性能</h4>
<h5 id="1-1-数据集划分"><a class="header-anchor" href="#1-1-数据集划分">¶</a>1.1 数据集划分</h5>
<ul>
<li><strong>训练集</strong>：用于训练模型的数据</li>
<li><strong>验证集</strong>：用于在训练过程中监控模型性能，帮助选择最佳模型</li>
<li><strong>测试集</strong>：独立的数据集，用于最终评估模型的性能</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从现有的问答对数据集中随机划分出 70% 用于训练，20% 用于验证，10% 用于测试</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取已生成的问答对数据</span></span><br><span class="line">data = pd.read_excel(<span class="string">&#x27;datang_baike_qa_pairs.xlsx&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集、验证集、测试集</span></span><br><span class="line">train_data, temp_data = train_test_split(data, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line">val_data, test_data = train_test_split(temp_data, test_size=<span class="number">0.33</span>, random_state=<span class="number">42</span>)  <span class="comment"># 20%验证集, 10%测试集</span></span><br></pre></td></tr></table></figure>
<h5 id="1-2-评估指标"><a class="header-anchor" href="#1-2-评估指标">¶</a>1.2  评估指标</h5>
<p>对于<code>问答对生成和问答系统</code>，常用的评估指标包括：</p>
<ul>
<li>
<p><strong>准确率（Accuracy）</strong>：回答正确的比例。</p>
<ul>
<li>适用于分类任务。</li>
</ul>
</li>
<li>
<p><strong>召回率（Recall）</strong>：模型能找到所有正确答案的比例。</p>
<ul>
<li>适用于存在较多负样本的场景。</li>
</ul>
</li>
<li>
<p><strong>精确率（Precision）</strong>：模型预测正确答案的比例。</p>
<ul>
<li>适用于需要关注结果精确性的场景。</li>
</ul>
</li>
<li>
<p><strong>F1分数</strong>：精确率和召回率的调和平均值.</p>
<ul>
<li>适用于需要平衡两者的场景。</li>
</ul>
</li>
<li>
<p><strong>BLEU分数</strong>：评估生成文本的质量.</p>
<ul>
<li>衡量生成的问题是否与目标问题语义接近。</li>
</ul>
</li>
<li>
<p><strong>示例</strong>：假设你有一个生成问答对的模型，使用 F1 分数来评估模型生成的问答是否与目标问答相匹配。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设模型预测的答案和实际答案如下</span></span><br><span class="line">y_true = [<span class="string">&quot;大唐不夜城是一个历史文化主题公园&quot;</span>, <span class="string">&quot;位于西安&quot;</span>]</span><br><span class="line">y_pred = [<span class="string">&quot;大唐不夜城是一个历史文化公园&quot;</span>, <span class="string">&quot;在西安&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算F1分数</span></span><br><span class="line">f1 = f1_score(y_true, y_pred, average=<span class="string">&#x27;micro&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;F1 Score: <span class="subst">&#123;f1&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="2-模型调优"><a class="header-anchor" href="#2-模型调优">¶</a>2.  模型调优</h4>
<ul>
<li>根据评估结果，对模型进行调优，包括但不限于模型架构、超参数和训练策略等</li>
</ul>
<h5 id="2-1-模型架构调优"><a class="header-anchor" href="#2-1-模型架构调优">¶</a>2.1  模型架构调优</h5>
<p>使用的是 <code>LangChain Chatchat</code> 大模型框架，可能需要关注以下几个方面：</p>
<ul>
<li>
<p><strong>层数和单元数</strong>：适当增加或减少模型的层数和单元数，以找到最佳的模型容量。</p>
</li>
<li>
<p><strong>注意力机制</strong>：调整注意力头数、多头注意力机制等，以提升模型对问答对关系的捕捉能力。</p>
</li>
<li>
<p><strong>示例</strong>：假设你在使用一个基础的 BERT 模型进行问答对生成，你可以通过增加模型的层数、增加注意力头数来尝试提升性能。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertConfig, BertModel</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用自定义的BERT配置</span></span><br><span class="line">config = BertConfig(</span><br><span class="line">    hidden_size=<span class="number">768</span>,    <span class="comment"># 增加模型的隐藏层大小</span></span><br><span class="line">    num_attention_heads=<span class="number">12</span>,  <span class="comment"># 增加注意力头数</span></span><br><span class="line">    num_hidden_layers=<span class="number">12</span>     <span class="comment"># 增加模型层数</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = BertModel(config)</span><br></pre></td></tr></table></figure>
<h5 id="2-2-超参数调优"><a class="header-anchor" href="#2-2-超参数调优">¶</a>2.2  超参数调优</h5>
<p>超参数调优是提升模型性能的关键步骤，可以使用以下几种方法：</p>
<ul>
<li><strong>学习率（Learning Rate）</strong>：调整学习率，过大或过小都会影响模型的收敛效果</li>
<li><strong>批次大小（Batch Size）</strong>：较大的批次大小可能提升训练效率，但可能导致模型欠拟合</li>
<li><strong>训练轮次（Epochs）</strong>：增加或减少训练轮次，避免过拟合或欠拟合</li>
</ul>
<p><strong>示例</strong>：可以使用 <code>GridSearchCV</code> 或 <code>RandomSearchCV</code> 来自动化地搜索超参数组合</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型架构</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_model</span>(<span class="params">optimizer=<span class="string">&#x27;adam&#x27;</span>, init=<span class="string">&#x27;glorot_uniform&#x27;</span></span>):</span><br><span class="line">    model = Sequential()</span><br><span class="line">    model.add(Dense(<span class="number">12</span>, input_dim=<span class="number">8</span>, kernel_initializer=init, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dense(<span class="number">8</span>, kernel_initializer=init, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dense(<span class="number">1</span>, kernel_initializer=init, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line">    model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, optimizer=optimizer, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义超参数组合</span></span><br><span class="line">param_grid = &#123;</span><br><span class="line">    <span class="string">&#x27;batch_size&#x27;</span>: [<span class="number">10</span>, <span class="number">20</span>, <span class="number">40</span>],</span><br><span class="line">    <span class="string">&#x27;epochs&#x27;</span>: [<span class="number">10</span>, <span class="number">50</span>, <span class="number">100</span>],</span><br><span class="line">    <span class="string">&#x27;optimizer&#x27;</span>: [<span class="string">&#x27;SGD&#x27;</span>, <span class="string">&#x27;Adam&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;init&#x27;</span>: [<span class="string">&#x27;glorot_uniform&#x27;</span>, <span class="string">&#x27;normal&#x27;</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化GridSearchCV</span></span><br><span class="line">model = KerasClassifier(build_fn=build_model, verbose=<span class="number">0</span>)</span><br><span class="line">grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-<span class="number">1</span>, cv=<span class="number">3</span>)</span><br><span class="line">grid_result = grid.fit(X, y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出最佳结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Best: <span class="subst">&#123;grid_result.best_score_&#125;</span> using <span class="subst">&#123;grid_result.best_params_&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h5 id="2-3-训练策略调整"><a class="header-anchor" href="#2-3-训练策略调整">¶</a>2.3  训练策略调整</h5>
<p>在训练过程中，你可以调整一些策略来提高模型性能：</p>
<ul>
<li><strong>学习率调整策略</strong>：使用学习率调度器（如 <code>ReduceLROnPlateau</code>）动态调整学习率</li>
<li><strong>正则化方法</strong>：使用 Dropout 或权重衰减来防止过拟合</li>
<li><strong>数据增强</strong>：通过数据增强技术（如同义词替换）增加数据多样性，提高模型鲁棒性</li>
</ul>
<p><strong>示例</strong>：在 PyTorch 中使用学习率调度器</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">from</span> torch.optim.lr_scheduler <span class="keyword">import</span> ReduceLROnPlateau</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义优化器</span></span><br><span class="line">optimizer = Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义学习率调度器</span></span><br><span class="line">scheduler = ReduceLROnPlateau(optimizer, <span class="string">&#x27;min&#x27;</span>, patience=<span class="number">3</span>, factor=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在训练循环中使用调度器</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    train_loss = train_epoch(model, train_loader, optimizer)</span><br><span class="line">    val_loss = validate_epoch(model, val_loader)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新学习率</span></span><br><span class="line">    scheduler.step(val_loss)</span><br></pre></td></tr></table></figure>
<h4 id="3-示例：结合项目进行调优"><a class="header-anchor" href="#3-示例：结合项目进行调优">¶</a>3. 示例：结合项目进行调优</h4>
<h5 id="评估模型性能"><a class="header-anchor" href="#评估模型性能">¶</a>评估模型性能</h5>
<ul>
<li>使用生成的问答对和相似问题对模型进行评估，计算精确率、召回率和 F1 分数</li>
<li>对于相似问题的生成，使用 BLEU 分数衡量模型生成问题的语义相似度</li>
</ul>
<h5 id="调优策略"><a class="header-anchor" href="#调优策略">¶</a>调优策略</h5>
<ul>
<li><strong>模型架构调整</strong>：根据评估结果，增加或减少模型的层数，并尝试不同的预训练模型（如 RoBERTa、GPT 等）</li>
<li><strong>超参数调优</strong>：调整学习率、批次大小、训练轮次，尝试不同的优化器（如 AdamW、SGD 等）</li>
<li><strong>训练策略调整</strong>：使用动态学习率调度、添加 Dropout 层防止过拟合、增加训练数据的多样性</li>
</ul>
<h5 id="实际应用"><a class="header-anchor" href="#实际应用">¶</a>实际应用</h5>
<ul>
<li>如果模型在某些类型的问题上表现不佳，可以针对这些类型的数据进行数据增强或微调</li>
<li>如果生成的相似问题质量不高，可以尝试不同的生成模型或增强生成策略（如使用预训练的 T5 模型）</li>
</ul>
<h4 id="4-总结"><a class="header-anchor" href="#4-总结">¶</a>4. 总结</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">模型评估：</span><br><span class="line">	根据任务需求选择适合的评估指标，如 F1 分数、BLEU 分数等</span><br><span class="line">模型调优：</span><br><span class="line">	通过调整模型架构、超参数和训练策略，提高模型性能</span><br><span class="line">示例应用：</span><br><span class="line">	结合你的项目实际需求，针对性地进行调优策略调整</span><br></pre></td></tr></table></figure>
<h3 id="九、将微调后的模型作为回答模块并通过API与前端交互"><a class="header-anchor" href="#九、将微调后的模型作为回答模块并通过API与前端交互">¶</a>九、将微调后的模型作为回答模块并通过API与前端交互</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">在 Langchain Chatchat 框架中，将微调后的模型作为回答模块并通过 API 与前端交互，实现智能问答功能，主要涉及以下几个步骤：</span><br><span class="line"></span><br><span class="line">	微调模型：</span><br><span class="line">		使用大唐不夜城的问答数据对基础语言模型进行微调</span><br><span class="line">	</span><br><span class="line">	集成微调模型：</span><br><span class="line">		将微调后的模型集成到Langchain Chatchat框架中，作为回答模块</span><br><span class="line">	</span><br><span class="line">	构建 API 接口：</span><br><span class="line">		使用 Flask、FastAPI 或 Django 等框架搭建 RESTful API 服务，使前端能够通过 HTTP 请求与后端模型交互</span><br><span class="line">	</span><br><span class="line">	前后端交互：</span><br><span class="line">		前端通过发送用户问题到 API 接口，后端调用微调模型生成回答并返回前端</span><br></pre></td></tr></table></figure>
<h4 id="1-微调模型"><a class="header-anchor" href="#1-微调模型">¶</a>1. 微调模型</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设你已经使用大唐不夜城的数据对预训练模型（如 BERT、GPT）进行了微调，并保存了微调后的模型</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Trainer, TrainingArguments, AutoModelForQuestionAnswering</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载预训练模型和数据集</span></span><br><span class="line">model_name = <span class="string">&quot;bert-base-uncased&quot;</span></span><br><span class="line">model = AutoModelForQuestionAnswering.from_pretrained(model_name)</span><br><span class="line"><span class="comment"># 假设微调的数据已经准备好</span></span><br><span class="line">train_dataset = ...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置训练参数</span></span><br><span class="line">training_args = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">&#x27;./results&#x27;</span>,          </span><br><span class="line">    num_train_epochs=<span class="number">3</span>,              </span><br><span class="line">    per_device_train_batch_size=<span class="number">16</span>,  </span><br><span class="line">    per_device_eval_batch_size=<span class="number">16</span>,   </span><br><span class="line">    warmup_steps=<span class="number">500</span>,                </span><br><span class="line">    weight_decay=<span class="number">0.01</span>,               </span><br><span class="line">    logging_dir=<span class="string">&#x27;./logs&#x27;</span>,            </span><br><span class="line">    logging_steps=<span class="number">10</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 Trainer 对象</span></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,                         </span><br><span class="line">    args=training_args,                  </span><br><span class="line">    train_dataset=train_dataset,         </span><br><span class="line">    eval_dataset=val_dataset             </span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始微调</span></span><br><span class="line">trainer.train()</span><br><span class="line"><span class="comment"># 保存微调后的模型</span></span><br><span class="line">model.save_pretrained(<span class="string">&quot;./fine_tuned_model&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="2-集成微调模型到Langchain-Chatchat"><a class="header-anchor" href="#2-集成微调模型到Langchain-Chatchat">¶</a>2. 集成微调模型到Langchain Chatchat</h4>
<h5 id="1-将微调模型加载到-Langchain-Chatchat"><a class="header-anchor" href="#1-将微调模型加载到-Langchain-Chatchat">¶</a>1. 将微调模型加载到 Langchain Chatchat</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在 Langchain Chatchat 的回答模块中加载微调后的模型</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForQuestionAnswering</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载微调后的模型</span></span><br><span class="line">model_path = <span class="string">&quot;./fine_tuned_model&quot;</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_path)</span><br><span class="line">model = AutoModelForQuestionAnswering.from_pretrained(model_path)</span><br></pre></td></tr></table></figure>
<h5 id="2-定义回答模块"><a class="header-anchor" href="#2-定义回答模块">¶</a>2. 定义回答模块</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在 Chatchat 中定义一个回答模块，该模块将接收用户问题，并调用微调模型生成答案</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">QAAnsweringModule</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model, tokenizer</span>):</span><br><span class="line">        self.model = model</span><br><span class="line">        self.tokenizer = tokenizer</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_answer</span>(<span class="params">self, question, context</span>):</span><br><span class="line">        inputs = self.tokenizer(question, context, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">        outputs = self.model(**inputs)</span><br><span class="line">        <span class="comment"># 提取答案逻辑</span></span><br><span class="line">        answer_start = torch.argmax(outputs.start_logits)  <span class="comment"># 答案开始位置</span></span><br><span class="line">        answer_end = torch.argmax(outputs.end_logits)      <span class="comment"># 答案结束位置</span></span><br><span class="line">        answer = self.tokenizer.decode(inputs.input_ids[<span class="number">0</span>][answer_start:answer_end+<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">return</span> answer</span><br></pre></td></tr></table></figure>
<h5 id="3-创建回答模块实例"><a class="header-anchor" href="#3-创建回答模块实例">¶</a>3. 创建回答模块实例</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qa_module = QAAnsweringModule(model, tokenizer)</span><br></pre></td></tr></table></figure>
<h4 id="3-构建API接口"><a class="header-anchor" href="#3-构建API接口">¶</a>3. 构建API接口</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">使用 Flask 或 FastAPI 框架创建 RESTful API 接口，将 Langchain Chatchat 集成到 API 中</span><br></pre></td></tr></table></figure>
<h5 id="1-使用-FastAPI-创建接口"><a class="header-anchor" href="#1-使用-FastAPI-创建接口">¶</a>1. 使用 FastAPI 创建接口</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Request</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义请求数据模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">QuestionRequest</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    question: <span class="built_in">str</span></span><br><span class="line">    context: <span class="built_in">str</span>  <span class="comment"># 用于提供上下文，如关于大唐不夜城的详细描述</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义 API 路由，接收前端请求并返回答案</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/qa&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_answer</span>(<span class="params">request: QuestionRequest</span>):</span><br><span class="line">    question = request.question</span><br><span class="line">    context = request.context</span><br><span class="line">    answer = qa_module.get_answer(question, context)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;answer&quot;</span>: answer&#125;</span><br></pre></td></tr></table></figure>
<h5 id="2-启动-FastAPI-服务器"><a class="header-anchor" href="#2-启动-FastAPI-服务器">¶</a>2. 启动 FastAPI 服务器</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uvicorn app:app --host <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span> --port <span class="number">8000</span></span><br></pre></td></tr></table></figure>
<h4 id="4-前后端交互"><a class="header-anchor" href="#4-前后端交互">¶</a>4. 前后端交互</h4>
<h5 id="1-前端发送请求"><a class="header-anchor" href="#1-前端发送请求">¶</a>1. 前端发送请求</h5>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 前端通过 HTTP 请求向 FastAPI 发送用户问题和上下文，并接收返回的答案</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">function</span> <span class="title function_">askQuestion</span>(<span class="params">question, context</span>) &#123;</span><br><span class="line">    <span class="keyword">const</span> response = <span class="keyword">await</span> <span class="title function_">fetch</span>(<span class="string">&quot;http://localhost:8000/qa&quot;</span>, &#123;</span><br><span class="line">        <span class="attr">method</span>: <span class="string">&quot;POST&quot;</span>,</span><br><span class="line">        <span class="attr">headers</span>: &#123;</span><br><span class="line">            <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/json&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">body</span>: <span class="title class_">JSON</span>.<span class="title function_">stringify</span>(&#123; <span class="attr">question</span>: question, <span class="attr">context</span>: context &#125;)</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="keyword">const</span> data = <span class="keyword">await</span> response.<span class="title function_">json</span>();</span><br><span class="line">    <span class="keyword">return</span> data.<span class="property">answer</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用示例</span></span><br><span class="line"><span class="keyword">const</span> question = <span class="string">&quot;大唐不夜城的开放时间是什么时候？&quot;</span>;</span><br><span class="line"><span class="keyword">const</span> context = <span class="string">&quot;大唐不夜城位于西安市，是一个以唐代文化为主题的文化旅游区...&quot;</span>;</span><br><span class="line"><span class="title function_">askQuestion</span>(question, context).<span class="title function_">then</span>(<span class="function"><span class="params">answer</span> =&gt;</span> <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;答案: &quot;</span>, answer));</span><br></pre></td></tr></table></figure>
<h5 id="2-后端处理请求"><a class="header-anchor" href="#2-后端处理请求">¶</a>2. 后端处理请求</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># FastAPI 接收到请求后，调用 Langchain Chatchat 的回答模块生成答案并返回给前端 </span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/qa&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_answer</span>(<span class="params">request: QuestionRequest</span>):</span><br><span class="line">    question = request.question</span><br><span class="line">    context = request.context</span><br><span class="line">    <span class="comment"># 调用微调后的模型获取答案</span></span><br><span class="line">    answer = qa_module.get_answer(question, context)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;answer&quot;</span>: answer&#125;</span><br></pre></td></tr></table></figure>
<h5 id="3-前端展示结果"><a class="header-anchor" href="#3-前端展示结果">¶</a>3. 前端展示结果</h5>
<ul>
<li>前端将返回的答案显示在用户界面上，用户可以看到由微调模型生成的智能回答</li>
</ul>
<h4 id="5-结合项目示例"><a class="header-anchor" href="#5-结合项目示例">¶</a>5. 结合项目示例</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">假设你已经有大唐不夜城的问答对数据，将以下步骤应用到你的项目中：</span><br><span class="line"></span><br><span class="line">	- 微调模型：用大唐不夜城的数据集（xlsx 文件）微调 BERT 或 GPT 模型</span><br><span class="line">	</span><br><span class="line">	- 模型集成：将微调后的模型加载到 Langchain Chatchat 框架中，创建一个自定义的回答模块</span><br><span class="line">	</span><br><span class="line">	- 构建 API 接口：使用 FastAPI 构建 RESTful API 接口，将问答模块暴露为 Web 服务</span><br><span class="line">	</span><br><span class="line">    - 前端交互：</span><br><span class="line">        - 用户在前端输入问题，如“大唐不夜城的门票价格是多少？”</span><br><span class="line">        - 前端将用户问题通过 API 请求发送到后端</span><br><span class="line">        - 后端微调模型处理问题，返回答案给前端</span><br><span class="line">        - 前端将答案展示给用户</span><br></pre></td></tr></table></figure>
<h3 id="十、全程开发流程规划（来自：ChatGPT）"><a class="header-anchor" href="#十、全程开发流程规划（来自：ChatGPT）">¶</a>十、全程开发流程规划（来自：ChatGPT）</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">基于你的实际项目情况，我们可以详细规划大模型应用的全程开发流程。以下是结合 Django + Vue + ElementUI + MySQL（或 MongoDB）的开发流程，以及如何集成微调后的 Langchain Chatchat 模型，并实现前后端交互</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">1. 项目环境配置</span><br><span class="line">	1.1 硬件环境</span><br><span class="line">        GPU 服务器：确保 AutoDL 云服务器配置了必要的 GPU 资源，并已安装 Langchain Chatchat 社区镜像</span><br><span class="line">        操作系统：建议使用 Ubuntu 18.04 或更高版本</span><br><span class="line">        </span><br><span class="line">	1.2 软件环境</span><br><span class="line">	后端：</span><br><span class="line">        Python 3.8+：用于 Django 开发</span><br><span class="line">        Django 3.x/4.x：用于后端 API 开发</span><br><span class="line">        FastAPI（可选）：可以单独用于模型微服务接口开发</span><br><span class="line">        Langchain Chatchat：集成微调后的大模型</span><br><span class="line">        MySQL/MongoDB：选择合适的数据库存储问答数据</span><br><span class="line">        SQLAlchemy（如果使用 MySQL）：ORM 框架</span><br><span class="line">        PyMongo（如果使用 MongoDB）：数据库操作工具</span><br><span class="line">	前端：</span><br><span class="line">        Vue 2.x/3.x：前端框架</span><br><span class="line">        ElementUI：Vue 的 UI 组件库，用于构建界面</span><br><span class="line">        axios：前端 HTTP 库，用于与后端 API 交互</span><br><span class="line">        </span><br><span class="line">    1.3 环境配置</span><br><span class="line">    - 安装依赖：安装 Python、Django、FastAPI、数据库驱动（如 pymysql、pymongo）</span><br><span class="line">    - 设置虚拟环境：</span><br><span class="line">        python3 -m venv venv</span><br><span class="line">        <span class="built_in">source</span> venv/bin/activate</span><br><span class="line">        pip install django fastapi sqlalchemy pymysql pymongo</span><br><span class="line">    - Django 项目创建：</span><br><span class="line">        django-admin startproject my_project</span><br><span class="line">        <span class="built_in">cd</span> my_project</span><br><span class="line">        django-admin startapp api</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2.</span> 数据预处理与模型微调</span><br><span class="line">    <span class="number">2.1</span> 数据预处理</span><br><span class="line">    	- 读取 xlsx 数据：提取大唐不夜城的问答对数据</span><br><span class="line">	    - 数据清洗：去除空值、重复值等</span><br><span class="line">    	- 格式转换：将数据转换为模型训练所需的格式，如 JSON、CSV 等</span><br><span class="line">        </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取xlsx文件</span></span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;data/datang_questions.xlsx&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据清洗</span></span><br><span class="line">df = df.dropna()  <span class="comment"># 去除空值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据转换为列表格式</span></span><br><span class="line">qa_pairs = df[[<span class="string">&#x27;问题&#x27;</span>, <span class="string">&#x27;答案&#x27;</span>]].to_dict(orient=<span class="string">&#x27;records&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存为JSON</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data/qa_pairs.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    json.dump(qa_pairs, f)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="number">2.2</span> 模型微调</span><br><span class="line">        - 选择模型：基于任务需求，选择 BERT、GPT 等模型</span><br><span class="line">        - 数据集划分：将数据分为训练集、验证集和测试集</span><br><span class="line">        - 训练与微调：</span><br><span class="line">            - 加载预训练模型和分词器</span><br><span class="line">            - 训练时选择合适的超参数（如学习率、batch size）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Trainer, TrainingArguments, AutoModelForQuestionAnswering</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载预训练模型和数据集</span></span><br><span class="line">model_name = <span class="string">&quot;bert-base-chinese&quot;</span></span><br><span class="line">model = AutoModelForQuestionAnswering.from_pretrained(model_name)</span><br><span class="line">tokenizer = ...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置训练参数</span></span><br><span class="line">training_args = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">&#x27;./results&#x27;</span>,</span><br><span class="line">    num_train_epochs=<span class="number">3</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">16</span>,</span><br><span class="line">    logging_dir=<span class="string">&#x27;./logs&#x27;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 Trainer 对象</span></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=training_args,</span><br><span class="line">    train_dataset=train_dataset,</span><br><span class="line">    eval_dataset=val_dataset</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line">trainer.train()</span><br><span class="line">model.save_pretrained(<span class="string">&quot;./fine_tuned_model&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">3.</span> 模型集成与 API 接口开发</span><br><span class="line">    <span class="number">3.1</span> Django 后端</span><br><span class="line">    创建 API 应用：</span><br><span class="line">        - 在 Django 项目中创建 api 应用，用于管理所有 API 接口</span><br><span class="line">        - 配置 urls.py 路由</span><br><span class="line">    定义模型接口：</span><br><span class="line">    	- 使用 Django REST framework 创建模型 API 接口</span><br><span class="line">    	- 或使用FastAPI独立创建模型微服务，并通过 Django 请求调用</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 Django 中使用 FastAPI</span></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> .models <span class="keyword">import</span> QAAnsweringModule  <span class="comment"># 微调后的模型集成</span></span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建问答模块实例</span></span><br><span class="line">qa_module = QAAnsweringModule(model, tokenizer)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义 API 路由</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/api/qa/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_answer</span>(<span class="params">request: QuestionRequest</span>):</span><br><span class="line">    question = request.question</span><br><span class="line">    context = request.context</span><br><span class="line">    answer = qa_module.get_answer(question, context)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;answer&quot;</span>: answer&#125;</span><br><span class="line"></span><br><span class="line">	数据库操作：</span><br><span class="line">        - 如果使用 MySQL，定义 Django 模型并使用 ORM 操作数据库</span><br><span class="line">        - 如果使用 MongoDB，配置 PyMongo 连接，操作数据库</span><br></pre></td></tr></table></figure>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">    <span class="number">3.2</span> 前端交互</span><br><span class="line">    创建 <span class="title class_">Vue</span> 项目：</span><br><span class="line">        - 使用 <span class="title class_">Vue</span> <span class="variable constant_">CLI</span> 创建前端项目</span><br><span class="line">        - 安装 <span class="title class_">ElementUI</span> 组件库</span><br><span class="line">    设计前端页面：</span><br><span class="line">        - 使用 <span class="title class_">ElementUI</span> 设计用户输入和答案显示界面</span><br><span class="line">        - 使用 axios 向 <span class="title class_">Django</span> 后端发送请求</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> axios <span class="keyword">from</span> <span class="string">&#x27;axios&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 问答请求函数</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">function</span> <span class="title function_">askQuestion</span>(<span class="params">question, context</span>) &#123;</span><br><span class="line">    <span class="keyword">const</span> response = <span class="keyword">await</span> axios.<span class="title function_">post</span>(<span class="string">&quot;http://localhost:8000/api/qa/&quot;</span>, &#123;</span><br><span class="line">        <span class="attr">question</span>: question,</span><br><span class="line">        <span class="attr">context</span>: context</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="keyword">return</span> response.<span class="property">data</span>.<span class="property">answer</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">	前端页面逻辑：</span><br><span class="line">		- 用户输入问题后，调用 askQuestion()，将结果显示在页面上</span><br><span class="line"></span><br><span class="line">&lt;template&gt;</span><br><span class="line">  &lt;div&gt;</span><br><span class="line">    &lt;el-input v-model=&quot;question&quot; placeholder=&quot;请输入您的问题&quot;&gt;&lt;/el-input&gt;</span><br><span class="line">    &lt;el-button @click=&quot;submitQuestion&quot;&gt;提交&lt;/el-button&gt;</span><br><span class="line">    &lt;p&gt;答案：&#123;&#123; answer &#125;&#125;&lt;/p&gt;</span><br><span class="line">  &lt;/div&gt;</span><br><span class="line">&lt;/template&gt;</span><br><span class="line"></span><br><span class="line">&lt;script&gt;</span><br><span class="line">export default &#123;</span><br><span class="line">  data() &#123;</span><br><span class="line">    return &#123;</span><br><span class="line">      question: &#x27;&#x27;,</span><br><span class="line">      answer: &#x27;&#x27;</span><br><span class="line">    &#125;;</span><br><span class="line">  &#125;,</span><br><span class="line">  methods: &#123;</span><br><span class="line">    async submitQuestion() &#123;</span><br><span class="line">      this.answer = await askQuestion(this.question, &quot;大唐不夜城相关背景信息&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">4. 部署与测试</span><br><span class="line">    后端部署：</span><br><span class="line">        使用 Gunicorn 和 Nginx 部署 Django 应用</span><br><span class="line">        如果使用 FastAPI 微服务，使用 Uvicorn 部署</span><br><span class="line">        </span><br><span class="line">    前端部署：</span><br><span class="line">    	构建 Vue 项目，生成静态文件，放置到 Django static 文件夹中</span><br><span class="line">    	</span><br><span class="line">    测试与调优：</span><br><span class="line">        测试前后端接口连通性，确保 API 能正确响应</span><br><span class="line">        根据用户反馈或测试结果，调整模型和前后端逻辑</span><br><span class="line">        </span><br><span class="line">5. 数据库选择与优化</span><br><span class="line">    MySQL：适合结构化数据的存储，支持复杂查询和事务操作</span><br><span class="line">    MongoDB：适合非结构化或半结构化数据，数据模式灵活</span><br><span class="line">    选择建议：</span><br><span class="line">        如果问答数据结构稳定，关系明确，使用 MySQL</span><br><span class="line">        如果需要存储灵活的文档格式，使用 MongoDB</span><br><span class="line">        </span><br><span class="line">6. 总结</span><br><span class="line">结合你的项目需求，以下是一个完整的开发流程：</span><br><span class="line">    - 配置环境，预处理数据并微调模型【当前还在这个流程】</span><br><span class="line">    - 在 Django 中集成微调模型，构建 API 接口</span><br><span class="line">    - 使用 Vue + ElementUI 开发前端页面，并实现与后端 API 的交互</span><br><span class="line">    - 部署项目，并不断调优，最终实现智能问答系统</span><br></pre></td></tr></table></figure>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        share
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://brocademaple.github.io/2024/09/21/CS_Notes/AI/%E3%80%90%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E3%80%91240922%E5%86%85%E5%AE%B9%E5%88%86%E4%BA%AB/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/" rel="tag">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CS-Notes/" rel="tag">CS Notes</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Project-Development/" rel="tag">Project Development</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2024/09/22/CS_Notes/PWN/%E3%80%90Pvvn%E3%80%91%E5%8F%AF%E8%83%BD%E6%98%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%90%A7/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            【Pvvn】可能是学习笔记吧
          
        </div>
      </a>
    
    
      <a href="/2024/09/19/CS_Notes/AI/%E3%80%90AI-Snova%E3%80%91%E6%95%B0%E6%8D%AE%E6%8F%90%E5%8F%96(Data-Extraction)--DOCX-extraction/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">【AI-Snova】数据提取(Data Extraction)--DOCX extraction</div>
      </a>
    
  </nav>

  
   
  
   
    <script src="https://cdn.staticfile.org/twikoo/1.4.18/twikoo.all.min.js"></script>
    <div id="twikoo" class="twikoo"></div>
    <script>
        twikoo.init({
            envId: ""
        })
    </script>
 
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2024
        <i class="ri-heart-fill heart_icon"></i> brocademaple
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer.png" alt="私の宝庫です"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friends">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/aboutMe">自分</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->
 <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.staticfile.org/mathjax/2.7.7/MathJax.js"></script>
<script src="https://cdn.staticfile.org/mathjax/2.7.7/config/TeX-AMS-MML_HTMLorMML-full.js"></script>
<script>
  var ayerConfig = {
    mathjax: true,
  };
</script>

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<script src="https://cdn.staticfile.org/animejs/3.2.1/anime.min.js"></script>

<script src="/js/clickBoom1.js"></script>
 
<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->
 
<script src="/js/dz.js"></script>
 
<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    <div id="music">
    
    
    
    <iframe frameborder="no" border="1" marginwidth="0" marginheight="0" width="200" height="52"
        src="//music.163.com/outchain/player?type=2&id=1983763439&auto=1&height=32"></iframe>
</div>

<style>
    #music {
        position: fixed;
        right: 15px;
        bottom: 0;
        z-index: 998;
    }
</style>
    
    

  </div>
</body>

</html>